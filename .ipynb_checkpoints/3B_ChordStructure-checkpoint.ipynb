{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472a49cc-5088-4e30-938c-28381a223849",
   "metadata": {},
   "source": [
    "# Looking at chord progressions\n",
    "\n",
    "In this notebook I'm going to look at chord progressions (overall, not for specific sections or anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd90dfd3-dfe8-439e-8822-1969008f7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import music_functions as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17962491-dc80-4cb5-8b12-d0bf71c29155",
   "metadata": {},
   "source": [
    "First, get chord-progression markov chains for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249372c2-2da9-470e-9eb1-c453665eee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/SECONDDRIVE/prog/ug/chord_dicts/\"\n",
    "\n",
    "for decade in ['1970', '1980', '1990', '2000', '2010']:\n",
    "    # read in the structure dictionary\n",
    "    decade_dir = input_dir + decade + \"/\"\n",
    "    structure_dict = mf.get_chord_structure_dict([decade_dir + \"/\" + x for x in os.listdir(decade_dir)])\n",
    "    \n",
    "    # read in the distribution stats (to know what section labels to use)\n",
    "    structure_vocab = pd.read_csv(\"Output/SongStructure/\"+ decade + \"_song_structure.csv\")\n",
    "    labels = [key for key in structure_vocab.iloc[:,0].values]\n",
    "    labels.remove(\"StartOfSong\")\n",
    "    \n",
    "    for label in labels:\n",
    "        structure_df = pd.DataFrame.from_dict(mf.clean_structure_dict(structure_dict[label], 10)).fillna(0)\n",
    "\n",
    "        for col in structure_df.columns:\n",
    "            structure_df[col] = structure_df[col]/sum(structure_df[col])\n",
    "\n",
    "        structure_df = structure_df.transpose()\n",
    "        \n",
    "        structure_df.to_csv(\"Output/SectionStructure/\" + decade + \"_\" + label + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e877b4-0c30-4b03-a1c0-1504e8c42469",
   "metadata": {},
   "source": [
    "TODO: then we want to do an overall chord progression markov chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf52722a-b132-4dbf-a6d4-cb60019023f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_dir = \"/Volumes/SECONDDRIVE/prog/ug/chord_dicts/1970/\"\n",
    "structure_dict = mf.get_chord_structure_dict([decade_dir + x for x in os.listdir(decade_dir)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e3f1b-8ada-40cd-ad88-c2aa6f79bedf",
   "metadata": {},
   "source": [
    "TODO: get chord statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1feec645-c27d-4fdb-b764-61f243e381ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/Volumes/SECONDDRIVE/prog/ug/chord_dicts/\"\n",
    "\n",
    "for decade in ['1970', '1980', '1990', '2000', '2010']:\n",
    "    # read in the structure dictionary\n",
    "    decade_dir = input_dir + decade + \"/\"\n",
    "\n",
    "    # create blank dataframe to store chord stats\n",
    "    df = pd.DataFrame(columns=['song_name', 'total_chords', 'chords_in_key_sig', 'chords_not_in_key_sig', \n",
    "                               'num_unique_chords', 'most_frequent_chords', 'tonic', 'tonic_frequency'])\n",
    "    \n",
    "    all_chord_dict = {}\n",
    "\n",
    "    for fname in os.listdir(decade_dir):\n",
    "\n",
    "\n",
    "        with open(decade_dir + fname) as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        tonic=data['Tonic']\n",
    "\n",
    "        all_chords = mf.get_all_chords_numeric(data)\n",
    "        \n",
    "        all_chord_dict[fname.split('.')[0]] = all_chords\n",
    "\n",
    "        in_key_sig = mf.numerals_major\n",
    "        tonic_frequency = all_chords['I']\n",
    "        if tonic.endswith(\"m\"):\n",
    "            in_key_sig = mf.numerals_minor\n",
    "            tonic_frequency = all_chords['i']\n",
    "\n",
    "        song_dict = {\n",
    "            'song_name': fname.split(\".\")[0],\n",
    "            'total_chords': sum([all_chords[x] for x in all_chords]),\n",
    "            'chords_in_key_sig': sum([all_chords[x] for x in all_chords if x in in_key_sig]),\n",
    "            'chords_not_in_key_sig': sum([all_chords[x] for x in all_chords if x not in in_key_sig]),\n",
    "            'num_unique_chords': len(list(all_chords.keys())),\n",
    "            'most_frequent_chords': ','.join([key for key in all_chords if all_chords[key] == max([all_chords[x] for x in all_chords])]),\n",
    "            'tonic': tonic,\n",
    "            'tonic_frequency': tonic_frequency\n",
    "        }\n",
    "\n",
    "        df = df.append(song_dict, ignore_index=True)\n",
    "        df.to_csv(\"Output/ChordStats/\" + decade + \".csv\", index=False)       \n",
    "        \n",
    "        with open(\"Output/ChordCounts/\" + decade + \".json\", \"w\") as outfile:\n",
    "            json.dump(all_chord_dict, outfile)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ace05-35f4-47bc-a838-314f55d9be80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
